{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a870a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random,shutil\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import neurokit2 as nk\n",
    "model=load_model(\"models/bestmodelall.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526a8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detector(file_path,sampled_rate):\n",
    "    file=pd.read_csv(file_path)\n",
    "    file=file.iloc[:,1]\n",
    "    _, rpeaks = nk.ecg_peaks(file, sampling_rate=sampled_rate)\n",
    "    return rpeaks['ECG_R_Peaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5977165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotator(patient):\n",
    "    directory=\"mid-evaluation-photos\"\n",
    "    record=pd.read_csv(\"mitbih_database/\"+patient+\".csv\")\n",
    "    df = pd.read_csv(\"mitbih_database/\"+patient+\"annotations.txt\", delimiter= '\\s+',index_col=False)\n",
    "    Sample=df[\"Sample\"]\n",
    "    Symbol=df[\"#\"]\n",
    "    try:\n",
    "        for l in range(len(Sample-1)):\n",
    "            signal=record.iloc[Sample[l]:Sample[l+1],1]\n",
    "            fig = plt.figure(frameon=False)\n",
    "            plt.plot(signal) \n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            filename = directory +\"/\"+patient+\"_\"+str(l)+\".png\"\n",
    "            fig.savefig(filename)\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.resize(im_gray, (128,128), interpolation = cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            plt.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f88332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_annotator(file_path,peaks,patient):\n",
    "    \n",
    "    patient=str(patient)\n",
    "    directory=\"mid-evaluation-photos\"\n",
    "    record=pd.read_csv(file_path)\n",
    "    Sample=peaks\n",
    "    try:\n",
    "        for l in range(len(Sample-1)):\n",
    "            signal=record.iloc[Sample[l]:Sample[l+1],1]\n",
    "            fig = plt.figure(frameon=False)\n",
    "            plt.plot(signal) \n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            filename = directory +\"/\"+patient+\"_\"+str(l)+\".png\"\n",
    "            fig.savefig(filename)\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.resize(im_gray, (128,128), interpolation = cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            plt.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505fb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(image_path):\n",
    "    name_list=os.listdir(image_path)\n",
    "    dictionary={\"fusion\":0,\"normal\":0,\"other\":0,\"sveb\":0,\"veb\":0}\n",
    "    destination_zero=\"classified/fusion\"\n",
    "    destination_one=\"classified/normal\"\n",
    "    destination_two=\"classified/other\"\n",
    "    destination_three=\"classified/sveb\"\n",
    "    destination_four=\"classified/veb\"\n",
    "    for name in name_list:\n",
    "        filepath=os.path.join(image_path,name)\n",
    "        image=cv2.imread(filepath)\n",
    "        gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        gray=gray/255.0\n",
    "        gray=gray.reshape(-1,128,128,1)\n",
    "        hai=model.predict(gray)\n",
    "        index=np.argmax(hai[0])\n",
    "        if index==0:\n",
    "            destination_path=os.path.join(destination_zero,name)\n",
    "            shutil.copyfile(filepath,destination_path)\n",
    "            dictionary[\"fusion\"]+=1\n",
    "        elif index==1:\n",
    "            destination_path=os.path.join(destination_one,name)\n",
    "            shutil.copyfile(filepath,destination_path)\n",
    "            dictionary[\"normal\"]+=1\n",
    "        elif index==2:\n",
    "            destination_path=os.path.join(destination_two,name)\n",
    "            shutil.copyfile(filepath,destination_path)\n",
    "            dictionary[\"other\"]+=1\n",
    "        elif index==3:\n",
    "            destination_path=os.path.join(destination_three,name)\n",
    "            shutil.copyfile(filepath,destination_path)\n",
    "            dictionary[\"sveb\"]+=1\n",
    "        elif index==4:\n",
    "            destination_path=os.path.join(destination_four,name)\n",
    "            shutil.copyfile(filepath,destination_path)\n",
    "            dictionary[\"veb\"]+=1\n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "        os.remove(filepath)\n",
    "    return dictionary\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc44564",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file=\"mitbih_database/200.csv\"\n",
    "peaks=peak_detector(csv_file,360)\n",
    "self_annotator(csv_file,peaks,100)\n",
    "#annotator(\"200\")\n",
    "filepath=\"mid-evaluation-photos\"\n",
    "output=predictor(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea5214",
   "metadata": {},
   "source": [
    "# Load NeuroKit and other useful packages\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 5]  # Bigger images\n",
    "\n",
    "#ecg_signal = nk.data(dataset=\"ecg_3000hz\")['ECG']\n",
    "\n",
    "#ecg_signal\n",
    "\n",
    "#ecg_signal.plot()\n",
    "\n",
    "#_, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=3000)\n",
    "\n",
    "#rpeaks\n",
    "\n",
    "# Visualize R-peaks in ECG signal\n",
    "#plot = nk.events_plot(rpeaks['ECG_R_Peaks'], ecg_signal)\n",
    "\n",
    "# Zooming into the first 5 R-peaks\n",
    "#plot = nk.events_plot(rpeaks['ECG_R_Peaks'][:5], ecg_signal[:20000])\n",
    "\n",
    "file=pd.read_csv(\"mitbih_database/100.csv\")\n",
    "\n",
    "file.columns\n",
    "\n",
    "file=file.iloc[:,1]\n",
    "\n",
    "_, rpeaks = nk.ecg_peaks(file, sampling_rate=360)\n",
    "\n",
    "# Visualize R-peaks in ECG signal\n",
    "#plot = nk.events_plot(rpeaks['ECG_R_Peaks'], file)\n",
    "\n",
    "# Zooming into the first 5 R-peaks\n",
    "#plot = nk.events_plot(rpeaks['ECG_R_Peaks'][:5], file[:20000])\n",
    "\n",
    "\n",
    "plot = nk.events_plot(rpeaks['ECG_R_Peaks'][:68], file[:20000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
